{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c0de6e",
   "metadata": {},
   "source": [
    "# One-Hot Encoding for DNA Sequences in Drug Development\n",
    "\n",
    "## Deep Conceptual Foundation\n",
    "\n",
    "### The Fundamental Problem: Why Categorical Data Breaks Statistical Methods\n",
    "\n",
    "In statistics and machine learning, nearly all algorithms rely on **numerical operations**: calculating distances, computing averages, measuring variance, and optimizing through gradient descent. These operations assume that numbers have **magnitude**, **order**, and **consistent spacing**.\n",
    "\n",
    "Categorical variables like DNA bases (A, T, G, C) have **none of these properties**:\n",
    "- **No magnitude**: 'A' is not \"larger\" or \"smaller\" than 'T'\n",
    "- **No order**: 'G' does not come \"before\" or \"after\" 'C' in any meaningful biological sense\n",
    "- **No spacing**: The \"distance\" between A and T is not comparable to the distance between G and C\n",
    "\n",
    "### What Breaks If We Ignore This?\n",
    "\n",
    "If we naively encode DNA bases as integers (A=1, C=2, G=3, T=4), we create **false mathematical relationships**:\n",
    "- The model \"learns\" that T is 4× larger than A\n",
    "- The average of A and T would be 2.5, which corresponds to C — a biologically meaningless operation\n",
    "- Distance calculations become arbitrary: |T - A| = 3, but |G - C| = 1, suggesting G and C are \"more similar\"\n",
    "\n",
    "In drug development, this leads to:\n",
    "- **QSAR models** learning numerical artifacts instead of chemical properties\n",
    "- **Binding affinity predictions** being distorted by fake geometric relationships\n",
    "- **Sequence-activity models** failing to generalize because they've learned the wrong patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geometric_intuition",
   "metadata": {},
   "source": [
    "## Geometric Intuition: From Number Line to Orthogonal Space\n",
    "\n",
    "### Naive Integer Encoding (WRONG)\n",
    "\n",
    "Imagine placing categories on a number line:\n",
    "```\n",
    "A     C     G           T\n",
    "1     2     3           4\n",
    "|-----|-----|-----------|---->\n",
    "```\n",
    "\n",
    "This creates **unequal distances** and **false ordering**. The model sees T as \"far\" from A, but C as \"close\" to A.\n",
    "\n",
    "### One-Hot Encoding (CORRECT)\n",
    "\n",
    "Instead, we embed each category as a **unit vector** in orthogonal space:\n",
    "\n",
    "```\n",
    "A = [1, 0, 0, 0]  →  points along axis 1\n",
    "C = [0, 1, 0, 0]  →  points along axis 2\n",
    "G = [0, 0, 1, 0]  →  points along axis 3\n",
    "T = [0, 0, 0, 1]  →  points along axis 4\n",
    "```\n",
    "\n",
    "**Key property**: Every pair of bases is **equidistant**.\n",
    "\n",
    "Using Euclidean distance: d(A, C) = √[(1-0)² + (0-1)² + (0-0)² + (0-0)²] = √2\n",
    "\n",
    "Similarly: d(A, T) = √2, d(G, C) = √2, etc.\n",
    "\n",
    "**This preserves biological neutrality** — no base is artificially \"closer\" to any other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toy_dataset_intro",
   "metadata": {},
   "source": [
    "## Concrete Numerical Example: Before vs After\n",
    "\n",
    "Let's take a tiny DNA sequence: **ATGC**\n",
    "\n",
    "### BEFORE One-Hot Encoding (Naive Integer Encoding)\n",
    "```\n",
    "Sequence: A  T  G  C\n",
    "Encoded:  1  4  3  2\n",
    "```\n",
    "\n",
    "**Problems**:\n",
    "- Mean = (1+4+3+2)/4 = 2.5 (nonsense)\n",
    "- Variance exists (but meaningless)\n",
    "- Distance |A-T| = 3, but |G-C| = 1 (arbitrary)\n",
    "\n",
    "### AFTER One-Hot Encoding\n",
    "```\n",
    "        A  C  G  T\n",
    "A  →  [ 1, 0, 0, 0 ]\n",
    "T  →  [ 0, 0, 0, 1 ]\n",
    "G  →  [ 0, 0, 1, 0 ]\n",
    "C  →  [ 0, 1, 0, 0 ]\n",
    "```\n",
    "\n",
    "**What Changed**:\n",
    "- Each base became a 4-dimensional vector\n",
    "- All pairwise distances are now equal (√2)\n",
    "- No false ordering exists\n",
    "\n",
    "**What Stayed the Same**:\n",
    "- The sequence order (ATGC)\n",
    "- The identity of each base\n",
    "- The biological meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formula_derivation",
   "metadata": {},
   "source": [
    "## Mathematical Derivation: Why This Encoding?\n",
    "\n",
    "### Starting from Requirements\n",
    "\n",
    "We need an encoding where:\n",
    "1. Each category is represented numerically\n",
    "2. No category is \"closer\" to any other\n",
    "3. The representation is unique and reversible\n",
    "\n",
    "### Building the Encoding\n",
    "\n",
    "**Step 1**: For K categories, create K-dimensional space (here K=4 for A, C, G, T)\n",
    "\n",
    "**Step 2**: Assign each category to a **standard basis vector** (unit vector along one axis)\n",
    "\n",
    "For category i: e_i = [0, 0, ..., 1, ..., 0] where 1 appears at position i\n",
    "\n",
    "**Step 3**: Verify equidistance\n",
    "\n",
    "Distance between any two categories i and j:\n",
    "```\n",
    "d(e_i, e_j) = √(Σ(e_i[k] - e_j[k])²)\n",
    "            = √((1-0)² + (0-1)² + 0² + ... + 0²)\n",
    "            = √(1 + 1)\n",
    "            = √2\n",
    "```\n",
    "\n",
    "**Why this works**: Because basis vectors are **orthogonal** (dot product = 0), they're all equally far apart in Euclidean space.\n",
    "\n",
    "**What breaks if we change it**:\n",
    "- Using [1, 2, 3, 4] → unequal distances\n",
    "- Using 3D space for 4 categories → categories become non-orthogonal\n",
    "- Using 5D space → introduces redundant dimensions (wastes computation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invariance_properties",
   "metadata": {},
   "source": [
    "## What One-Hot Encoding Changes and Preserves\n",
    "\n",
    "### Changes (Intentional)\n",
    "- **Dimensionality**: 1D (single category) → KD (K-dimensional vector)\n",
    "- **Data type**: Categorical string → Binary numerical matrix\n",
    "- **Distance metric**: Undefined → Well-defined Euclidean distance\n",
    "\n",
    "### Preserves (Critical)\n",
    "- **Sequence order**: ATGC remains in order [A_vec, T_vec, G_vec, C_vec]\n",
    "- **Identity**: Each base retains unique representation\n",
    "- **Biological meaning**: No artificial chemical relationships introduced\n",
    "- **Reversibility**: Can decode back to original categories\n",
    "\n",
    "### Cannot Do (Limitations)\n",
    "- Cannot capture biological similarity (e.g., purines vs pyrimidines)\n",
    "- Cannot encode chemical properties (hydrogen bonding, molecular weight)\n",
    "- Cannot represent sequence context (neighboring bases)\n",
    "\n",
    "For these, you need **feature engineering** or **embedding layers** in neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drug_dev_context",
   "metadata": {},
   "source": [
    "## Drug Development Context\n",
    "\n",
    "### Where DNA Sequences Appear in Drug Discovery\n",
    "\n",
    "1. **Target Gene Sequences**: Identifying mutations in disease-related genes\n",
    "2. **Aptamer Design**: Creating oligonucleotide drugs that bind specific targets\n",
    "3. **CRISPR Guide Design**: Engineering sequences for gene editing therapies\n",
    "4. **Pharmacogenomics**: Predicting drug response from patient genetic variants\n",
    "\n",
    "### How Sequence Data is Obtained\n",
    "- **Next-Generation Sequencing (NGS)**: High-throughput DNA/RNA sequencing\n",
    "- **Sanger Sequencing**: Traditional method for targeted regions\n",
    "- **PCR Amplification**: Copying specific sequences for analysis\n",
    "\n",
    "### Relevance to ML in Drug Development\n",
    "\n",
    "**QSAR (Quantitative Structure-Activity Relationship)**:\n",
    "- For nucleotide-based drugs, sequences must be encoded before predicting activity\n",
    "- One-hot encoding enables distance-based similarity searches\n",
    "\n",
    "**Screening Pipelines**:\n",
    "- Virtual screening of aptamer libraries requires numerical sequence representation\n",
    "- Models trained on one-hot encoded sequences can rank candidates\n",
    "\n",
    "**Model Training**:\n",
    "- Neural networks require numerical input tensors\n",
    "- One-hot encoding provides the first layer input for sequence models\n",
    "\n",
    "### What Breaks in Real Pipelines Without Proper Encoding\n",
    "\n",
    "1. **Distance-based clustering**: K-means, hierarchical clustering produce nonsense groupings\n",
    "2. **Regression models**: Linear regression coefficients become uninterpretable\n",
    "3. **Neural networks**: Models learn encoding artifacts instead of biological patterns\n",
    "4. **Cross-validation**: Performance metrics are inflated due to false patterns\n",
    "5. **Biological interpretation**: Cannot explain which bases drive predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "implementation_intro",
   "metadata": {},
   "source": [
    "## Implementation in Python\n",
    "\n",
    "We'll now implement one-hot encoding step-by-step using scikit-learn's `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1_data_prep",
   "metadata": {},
   "source": [
    "### Step 1: Preparing the DNA Sequence\n",
    "\n",
    "The sequence must be converted into a **column vector** (2D array with shape (n, 1)) because:\n",
    "- scikit-learn encoders expect 2D input (samples × features)\n",
    "- Each nucleotide is treated as an independent observation\n",
    "- This format matches the convention for feature matrices in ML\n",
    "\n",
    "We'll use a simple 4-base sequence: **ATGC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b359b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Numerical computing library for array operations\n",
    "\n",
    "# Convert string \"ATGC\" into a list of individual characters, then to numpy array\n",
    "# reshape(-1, 1) converts 1D array [A, T, G, C] to 2D column vector [[A], [T], [G], [C]]\n",
    "# -1 means \"infer this dimension\" (here: 4 rows), 1 means 1 column\n",
    "sequence = np.array(list(\"ATGC\")).reshape(-1, 1)\n",
    "\n",
    "sequence  # Display the prepared sequence array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2_encoder_setup",
   "metadata": {},
   "source": [
    "### Step 2: Defining the One-Hot Encoder\n",
    "\n",
    "We configure the encoder with **explicit category ordering** to ensure:\n",
    "- **Reproducibility**: Column order stays consistent across different runs\n",
    "- **Semantic clarity**: We always know column 0 = A, column 1 = C, etc.\n",
    "- **Safety**: Prevents automatic reordering based on alphabetical or frequency-based sorting\n",
    "\n",
    "The `sparse_output=False` parameter returns a dense numpy array instead of a sparse matrix, which is easier to inspect and use in most ML pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef64d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder  # Import the encoding transformer\n",
    "\n",
    "# Initialize encoder with explicit category order\n",
    "encoder = OneHotEncoder(\n",
    "    categories=[['A', 'C', 'G', 'T']],  # Explicitly define the order: A, C, G, T (columns 0, 1, 2, 3)\n",
    "    sparse_output=False  # Return dense numpy array instead of sparse matrix for easier inspection\n",
    ")\n",
    "\n",
    "encoder  # Display the encoder configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3_encoding",
   "metadata": {},
   "source": [
    "### Step 3: Applying One-Hot Encoding\n",
    "\n",
    "The `fit_transform()` method performs two operations:\n",
    "1. **fit()**: Learns the mapping from categories to column indices\n",
    "2. **transform()**: Converts the input into the one-hot encoded matrix\n",
    "\n",
    "The output is a **binary matrix** where:\n",
    "- Each row corresponds to one nucleotide in the sequence\n",
    "- Each column corresponds to one possible base (A, C, G, T)\n",
    "- A value of 1 indicates \"this base is present\"\n",
    "- A value of 0 indicates \"this base is absent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de5d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform: learn the category-to-column mapping AND apply the encoding in one step\n",
    "# Input: [[A], [T], [G], [C]] (4 samples, 1 feature)\n",
    "# Output: 4×4 binary matrix (4 samples, 4 one-hot features)\n",
    "one_hot_matrix = encoder.fit_transform(sequence)\n",
    "\n",
    "print(\"--- Sequence: ATGC ---\")  # Display original sequence for reference\n",
    "print(\"Columns: [A, C, G, T]\")  # Remind which column corresponds to which base\n",
    "print(one_hot_matrix)  # Display the encoded matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpretation",
   "metadata": {},
   "source": [
    "## Interpreting the Output\n",
    "\n",
    "The resulting matrix should be:\n",
    "```\n",
    "[[1. 0. 0. 0.]  ← First nucleotide is A (column 0 = 1)\n",
    " [0. 0. 0. 1.]  ← Second nucleotide is T (column 3 = 1)\n",
    " [0. 0. 1. 0.]  ← Third nucleotide is G (column 2 = 1)\n",
    " [0. 1. 0. 0.]] ← Fourth nucleotide is C (column 1 = 1)\n",
    "```\n",
    "\n",
    "### Verification\n",
    "- Each row sums to 1.0 (exactly one base per position)\n",
    "- All values are 0 or 1 (binary encoding)\n",
    "- Matrix shape is (4, 4): 4 nucleotides × 4 possible bases\n",
    "\n",
    "### Next Steps in Real Pipelines\n",
    "This matrix can now be:\n",
    "- Fed into neural networks as input features\n",
    "- Used in distance calculations for clustering\n",
    "- Concatenated with other molecular descriptors for QSAR modeling\n",
    "- Processed by convolutional layers to detect sequence motifs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
